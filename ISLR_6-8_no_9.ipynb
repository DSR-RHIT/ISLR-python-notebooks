{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISLR Sec 6-8 Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression,RidgeCV,LassoCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# load data that has been cleaned\n",
    "df = pd.read_csv('../Data/College.csv',index_col=0)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert qualitative data to \"one-hot-encoding\"\n",
    "df = pd.get_dummies(df,columns=['Private'])\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = df.drop('Apps',axis=1).values\n",
    "y = df.Apps.values\n",
    "y = np.reshape(y,(len(y),1))\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) ordinary linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR = LinearRegression(normalize=True)\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred = LR.predict(x_test)\n",
    "MSE = mean_squared_error(y_test,y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "print('linear regression RMSE = %0.3f' % RMSE)\n",
    "print()\n",
    "print('intercept = %0.3f' % LR.intercept_)\n",
    "col = df.drop('Apps',axis=1).columns\n",
    "print(pd.DataFrame(LR.coef_,columns=col).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 10**np.linspace(5,-5,100)\n",
    "LR_ridge = RidgeCV(alphas=alpha,normalize=True)\n",
    "LR_ridge.fit(x_train,y_train)\n",
    "y_pred = LR_ridge.predict(x_test)\n",
    "MSE = mean_squared_error(y_test,y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "print('ridge regression RMSE = %0.3f' % RMSE)\n",
    "print('optimal alpha = %0.3f' % LR_ridge.alpha_)\n",
    "print()\n",
    "print('intercept = %0.3f' % LR_ridge.intercept_)\n",
    "col = df.drop('Apps',axis=1).columns\n",
    "print(pd.DataFrame(LR_ridge.coef_,columns=col).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (d) lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 10**np.linspace(5,-5,100)\n",
    "LR_lasso = LassoCV(alphas=alpha,normalize=True)\n",
    "LR_lasso.fit(x_train,y_train.flatten())\n",
    "y_pred = LR_lasso.predict(x_test)\n",
    "MSE = mean_squared_error(y_test,y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "print('lasso regression RMSE = %0.3f' % RMSE)\n",
    "print('optimal alpha = %0.3f' % LR_lasso.alpha_)\n",
    "print()\n",
    "print('intercept = %0.3f' % LR_lasso.intercept_)\n",
    "col = df.drop('Apps',axis=1).columns\n",
    "coef = LR_lasso.coef_\n",
    "coef = np.reshape(coef,(1,len(coef)))\n",
    "print(pd.DataFrame(coef,columns=col).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially no difference in prediction accuracy between ordinary, ridge and lasso regression. However, lasso has distinct advantage of zeroing out many coefficients, simplying the model considerably and making it easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
