{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISLR_5-3-1_to_3\n",
    "\n",
    "### 5-3-1 The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load clean version of data set\n",
    "df = pd.read_csv('../Data/Auto-cleaned.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x='horsepower',y='mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data with fixed random state\n",
    "x = df.horsepower.values\n",
    "x = x.reshape((len(x),1))\n",
    "y = df.mpg.values\n",
    "y = y.reshape((len(y),1))\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=196,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit linear regression & compute MSE\n",
    "LR = LinearRegression()\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred = LR.predict(x_train)\n",
    "MSE = mean_squared_error(y_train,y_pred)\n",
    "print('linear, training, mean square error = %0.2f' % MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit quadratic regression & compute MSE\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train = poly.fit_transform(x_train)\n",
    "LR.fit(X_train,y_train)\n",
    "y_pred = LR.predict(X_train)\n",
    "MSE = mean_squared_error(y_train,y_pred)\n",
    "print('quadratic, training, mean square error = %0.2f' % MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5-3-2 Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE = cross_val_score(LR,x,y,cv=len(y),scoring='mean_squared_error')\n",
    "print('number of cross-validation folds = %d' % len(MSE))\n",
    "print('average MSE test error %0.2f' % MSE.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average MSE score is negative! This output suggests to me that computer scientists have a greater influence on scikit learn than mathematicians. I believe, for most mathematicians, a negative MSE output would be a show stopper. The reason for the negative sign is to make the API design of scikit learn more uniform and pluggible in the grid search routine which maximizes the score. The problem that is being solved is that we want to minimize MSE and so by introduction of the minus sign we can can instead maximize it. For further details see: \n",
    "\n",
    " MSE is negative when returned by cross_val_score #2439 \n",
    " https://github.com/scikit-learn/scikit-learn/issues/2439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# leave-one-out cross-validation to select optimal polynomial degree\n",
    "results = []\n",
    "for k in range(5):\n",
    "    poly = PolynomialFeatures(degree=k+1)\n",
    "    X = poly.fit_transform(x)\n",
    "    MSE = -1.0*cross_val_score(LR,X,y,cv=len(y),scoring='mean_squared_error')\n",
    "    results.append([k+1,MSE.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=pd.DataFrame(results,columns=['degree','average test MSE'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a sharp improvement for k = 2 (quadratic fit) and not much improvement after that. A good rule of thumb is to use the simplest model that we find acceptible. We choose the quadratic fit. (Note: I converted the MSE scores back to positive numbers by multiplying by -1.0, so no one will laugh at me.) You should have a good understanding of the issue first before you manually change a score! and also carefully document what you have done!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3-3 k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10 fold cross-validation to select optimal polynomial degree\n",
    "results = []\n",
    "for k in range(5):\n",
    "    poly = PolynomialFeatures(degree=k+1)\n",
    "    X = poly.fit_transform(x)\n",
    "    MSE = -1.0*cross_val_score(LR,X,y,cv=10,scoring='mean_squared_error')\n",
    "    results.append([k+1,MSE.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=pd.DataFrame(results,columns=['degree','average test MSE'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors are higher as expected because we have a smaller training set with 10 fold cross-validation compared to leave-one-out cross-validation. (The textbook has the errors about the same. Not sure why there is not a better match to the numbers above.) Note 10 fold cross-validation is much faster than leave one out cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
