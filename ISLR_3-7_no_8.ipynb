{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISLR Exercises 3-7 Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Auto.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean data by forcing conversion to numerical values and possibly to NaN values\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'],errors='coerce')\n",
    "# remove rows with NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create linear regression object\n",
    "LR = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit (train) linear model\n",
    "x = df.horsepower.values\n",
    "y = df.mpg.values\n",
    "# Pandas and Scikit Learn objects don't play nicely together yet, but people are working on it.\n",
    "x = np.resize(x,(len(x),1))\n",
    "y = np.resize(y,(len(y),1))\n",
    "LR.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coefficients\n",
    "print 'slope = %f' % LR.coef_\n",
    "print 'intercept = %f' % LR.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fraction of variation explained by predictor(s)\n",
    "print 'R-sqr = %f' % LR.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standard error\n",
    "yp = LR.predict(x)\n",
    "MSE = mean_squared_error(yp,y)\n",
    "se = np.sqrt(MSE)\n",
    "print 'se = %f' % se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, R give $se=4.91$ because it uses a more accurate 390 degrees of freedom instead of the 392 used in the above calculations. (Degrees of freedom (DOF) equals number of data points minus number of coefficients (parameters).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se_R = se*392/390\n",
    "print 'se computed by R = %f' % se_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate points to plot least squares line\n",
    "xo = np.resize(np.linspace(x.min(),x.max(),101),(101,1))\n",
    "yo = LR.predict(xo)\n",
    "\n",
    "# plot points and least squares line.\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x,y)           \n",
    "ax.plot(xo,yo) \n",
    "ax.set_xlabel('horsepower')\n",
    "ax.set_ylabel('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot residuals \n",
    "yp = LR.predict(x)\n",
    "e = y - yp\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(yp,e) \n",
    "ax.set_xlabel('fitted values')\n",
    "ax.set_ylabel('residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curve in the plot of the residuals (fitting errors) suggests a nonlinear curve might give a better fit. Also, variation is increasing suggesting a transformation of the data may make variations about the fitted function more uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
